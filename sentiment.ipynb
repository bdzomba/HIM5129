{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Natural Language Processing : Sentiment Analysis in Python\n",
    "\n",
    "#The process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral.\n",
    "\n",
    " \n",
    "\n",
    "#Text analysis has changed between Python 2 and Python 3 due to changes in the way Python handles encoding of files.  Therefor, this code works with Python version 3.x but may or may not work with Python 2.  Code that works with Python 2 will most likely not work in 3 without major code updates to indicate a different encoding of the text file.\n",
    "\n",
    " \n",
    "\n",
    "#We will use a hard coded piece of text for our example.  Ideally you would use a text file rather than hard coding. I copied comments from the Temple Health System facebook page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great','better', 'best', 'excellent' ':)' ]\n",
    "\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', 'discriminated', 'rude', 'careless' ':(' ]\n",
    "\n",
    "neutral_vocab = [ 'sick','the','stay','was','is','visit','did','know','words','not' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = negative_features + positive_features + neutral_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "neg = 0\n",
    "\n",
    "pos = 0\n",
    "\n",
    "sentence = \"I’m an employee here and on Thursday I suffered from an anaphylactic reaction. I was rushed to the ER and my care was excellent. I was frightened, I couldn’t breath right, hives everywhere, completely panicked. The nursing staff calmed me and walked me through everything that was happening, I got the treatment I needed and feeling much better. I wish I could remember everyone names that treated me. I thank you from the bottom of my heart. The best emergency care ever!\"\n",
    "\n",
    "sentence = sentence.lower()\n",
    "\n",
    "words = sentence.split(' ')\n",
    "\n",
    "for word in words:\n",
    "\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "\n",
    "    if classResult == 'neg':\n",
    "\n",
    "        neg = neg + 1\n",
    "\n",
    "    if classResult == 'pos':\n",
    "\n",
    "        pos = pos + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.524390243902439\n",
      "Negative: 0.3902439024390244\n"
     ]
    }
   ],
   "source": [
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "\n",
    "print('Negative: ' + str(float(neg)/len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I made up a comment and adjusted some of the words in the code.\n",
    "\n",
    " \n",
    "\n",
    "import nltk.classify.util\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great','better', 'best', 'excellent' ':)' ]\n",
    "\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', 'hateful' 'discriminated', 'rude', 'careless' ':(' ]\n",
    "\n",
    "neutral_vocab = [ 'sick','the','stay','was','is','visit','did','know','words','not' ]\n",
    "\n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = negative_features + positive_features + neutral_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)  \n",
    "\n",
    "# Predict\n",
    "\n",
    "neg = 0\n",
    "\n",
    "pos = 0\n",
    "\n",
    "sentence = \"This was the worst care I ever experience! The nurses were rude and hateful. I felt discriminated against by the rude staff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sentence.lower()\n",
    "\n",
    "words = sentence.split(' ')\n",
    "\n",
    "for word in words:\n",
    "\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "\n",
    "    if classResult == 'neg':\n",
    "\n",
    "        neg = neg + 1\n",
    "\n",
    "    if classResult == 'pos':\n",
    "\n",
    "        pos = pos + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.36363636363636365\n",
      "Negative: 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "\n",
    "print('Negative: ' + str(float(neg)/len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
